import streamlit as st
import pandas as pd
import plotly.express as px
import requests
import json
import os
from datetime import datetime
from dotenv import load_dotenv

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Naver Market Insights", layout="wide", page_icon="âš¡")

# CSS ìŠ¤íƒ€ì¼ë§
st.markdown("""
    <style>
    .main { background-color: #f8f9fa; }
    .stMetric { background-color: #ffffff; padding: 15px; border-radius: 10px; box-shadow: 0 2px 4px rgba(0,0,0,0.05); }
    h1, h2, h3 { color: #1a237e; font-family: 'Outfit', sans-serif; }
    .stTabs [data-baseweb="tab-list"] { gap: 10px; }
    .stTabs [data-baseweb="tab"] {
        padding: 10px 20px;
        background-color: #eee;
        border-radius: 5px 5px 0 0;
        font-weight: 600;
    }
    .stTabs [aria-selected="true"] { background-color: #ffffff; border-top: 4px solid #3f51b5; color: #3f51b5; }
    div[data-testid="stSidebar"] { background-color: #ffffff; border-right: 1px solid #dee2e6; }
    </style>
""", unsafe_allow_html=True)

# --- ì¸ì¦ ë° ê²½ë¡œ ì„¤ì • ---
def get_api_keys():
    """ë„¤ì´ë²„ API í‚¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤. (Cloud Secrets ë° ë¡œì»¬ .env ì§€ì›)"""
    cid, csec = None, None
    
    # 1. Streamlit Secrets (Cloud ë°°í¬ì‹œ)
    try:
        if 'NAVER_CLIENT_ID' in st.secrets:
            cid = st.secrets['NAVER_CLIENT_ID']
            csec = st.secrets['NAVER_CLIENT_SECRET']
    except Exception:
        pass
    
    # 2. ë¡œì»¬ .env íŒŒì¼
    if not cid or not csec:
        env_path = os.path.join(os.path.dirname(__file__), '.env')
        if os.path.exists(env_path):
            load_dotenv(env_path, override=True)
            cid = os.getenv('NAVER_CLIENT_ID')
            csec = os.getenv('NAVER_CLIENT_SECRET')

    if cid: cid = str(cid).strip().strip("'").strip('"')
    if csec: csec = str(csec).strip().strip("'").strip('"')
    
    return cid, csec

CLIENT_ID, CLIENT_SECRET = get_api_keys()
HEADERS = {"X-Naver-Client-Id": CLIENT_ID, "X-Naver-Client-Secret": CLIENT_SECRET, "Content-Type": "application/json"}

# --- ì‹¤ì‹œê°„ API í˜¸ì¶œ í•¨ìˆ˜ ---
@st.cache_data(ttl=600)
def fetch_realtime_trend(keywords, start_date, end_date, gender=None, ages=None):
    """ë„¤ì´ë²„ ê²€ìƒ‰ì–´ íŠ¸ë Œë“œ API í˜¸ì¶œ (ì„±ë³„/ì—°ë ¹ í•„í„° ì¶”ê°€)"""
    if not CLIENT_ID or not CLIENT_SECRET: return None, "ì¸ì¦ í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    url = "https://openapi.naver.com/v1/datalab/search"
    body = {
        "startDate": start_date, "endDate": end_date,
        "timeUnit": "date",
        "keywordGroups": [{"groupName": k, "keywords": [k]} for k in keywords]
    }
    
    if gender:
        body["gender"] = gender
    if ages and len(ages) > 0:
        body["ages"] = ages
        
    res = requests.post(url, headers=HEADERS, data=json.dumps(body))
    if res.status_code == 200:
        dfs = [pd.DataFrame(r['data']).assign(keyword=r['title']) for r in res.json()['results']]
        return pd.concat(dfs), None
    return None, f"Trend API Error: {res.status_code}"

@st.cache_data(ttl=600)
def fetch_realtime_shopping(keywords):
    """ë„¤ì´ë²„ ì‡¼í•‘ ê²€ìƒ‰ API í˜¸ì¶œ (ë‹¤ì¤‘ í‚¤ì›Œë“œ í†µí•©)"""
    if not CLIENT_ID or not CLIENT_SECRET: return None, "ì¸ì¦ í‚¤ ë¯¸ì„¤ì •"
    all_items = []
    for kw in keywords:
        url = f"https://openapi.naver.com/v1/search/shop.json?query={kw}&display=100"
        res = requests.get(url, headers=HEADERS)
        if res.status_code == 200:
            items = res.json().get('items', [])
            for item in items:
                item['search_keyword'] = kw
            all_items.extend(items)
    return pd.DataFrame(all_items) if all_items else None, None

@st.cache_data(ttl=600)
def fetch_realtime_blog(keywords):
    """ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê²€ìƒ‰ API í˜¸ì¶œ (ë‹¤ì¤‘ í‚¤ì›Œë“œ í†µí•©)"""
    if not CLIENT_ID or not CLIENT_SECRET: return None, "ì¸ì¦ í‚¤ ë¯¸ì„¤ì •"
    all_items = []
    for kw in keywords:
        url = f"https://openapi.naver.com/v1/search/blog.json?query={kw}&display=100"
        res = requests.get(url, headers=HEADERS)
        if res.status_code == 200:
            items = res.json().get('items', [])
            for item in items:
                item['search_keyword'] = kw
            all_items.extend(items)
    return pd.DataFrame(all_items) if all_items else None, None

@st.cache_data(ttl=600)
def fetch_realtime_cafe(keywords):
    """ë„¤ì´ë²„ ì¹´í˜ ê²€ìƒ‰ API í˜¸ì¶œ (ë‹¤ì¤‘ í‚¤ì›Œë“œ í†µí•©)"""
    if not CLIENT_ID or not CLIENT_SECRET: return None, "ì¸ì¦ í‚¤ ë¯¸ì„¤ì •"
    all_items = []
    for kw in keywords:
        url = f"https://openapi.naver.com/v1/search/cafearticle.json?query={kw}&display=100"
        res = requests.get(url, headers=HEADERS)
        if res.status_code == 200:
            items = res.json().get('items', [])
            for item in items:
                item['search_keyword'] = kw
            all_items.extend(items)
    return pd.DataFrame(all_items) if all_items else None, None

@st.cache_data(ttl=600)
def fetch_realtime_news(keywords):
    """ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ API í˜¸ì¶œ (ë‹¤ì¤‘ í‚¤ì›Œë“œ í†µí•©)"""
    if not CLIENT_ID or not CLIENT_SECRET: return None, "ì¸ì¦ í‚¤ ë¯¸ì„¤ì •"
    all_items = []
    for kw in keywords:
        url = f"https://openapi.naver.com/v1/search/news.json?query={kw}&display=100"
        res = requests.get(url, headers=HEADERS)
        if res.status_code == 200:
            items = res.json().get('items', [])
            for item in items:
                item['search_keyword'] = kw
            all_items.extend(items)
    return pd.DataFrame(all_items) if all_items else None, None

@st.cache_data(ttl=600)
def fetch_shopping_insight_trend(cat_id, keywords, start_date, end_date):
    """ì‡¼í•‘ì¸ì‚¬ì´íŠ¸ ë¶„ì•¼ ë‚´ í‚¤ì›Œë“œ í´ë¦­ íŠ¸ë Œë“œ API í˜¸ì¶œ"""
    if not CLIENT_ID or not CLIENT_SECRET: 
        return None, "ì¸ì¦ í‚¤ ë¯¸ì„¤ì •", None
    
    url = "https://openapi.naver.com/v1/datalab/shopping/category/keywords"
    body = {
        "startDate": start_date, 
        "endDate": end_date,
        "timeUnit": "date",
        "category": cat_id,
        "keyword": [{"name": k, "param": [k]} for k in keywords]
    }
    
    res = requests.post(url, headers=HEADERS, data=json.dumps(body))
    
    # ì‘ë‹µ ì „ì²´ë¥¼ ì €ì¥ (ë””ë²„ê¹…ìš©)
    response_data = None
    try:
        response_data = res.json()
    except:
        pass
    
    if res.status_code == 200:
        results = response_data.get('results', []) if response_data else []
        
        if not results:
            # ë¹ˆ ê²°ê³¼ - APIëŠ” ì„±ê³µí–ˆì§€ë§Œ ë°ì´í„°ê°€ ì—†ìŒ
            return pd.DataFrame(), None, response_data
        
        dfs = []
        for r in results:
            if 'data' in r and r['data']:
                df = pd.DataFrame(r['data'])
                df['keyword'] = r['title']
                dfs.append(df)
        
        if dfs:
            return pd.concat(dfs), None, response_data
        else:
            return pd.DataFrame(), None, response_data
    else:
        # API ì—ëŸ¬
        error_msg = f"API ì˜¤ë¥˜ (ìƒíƒœì½”ë“œ: {res.status_code})"
        if response_data and 'errorMessage' in response_data:
            error_msg += f" - {response_data['errorMessage']}"
        return None, error_msg, response_data


@st.cache_data(ttl=600)
def fetch_shopping_insight_demographics(cat_id):
    """ì‡¼í•‘ì¸ì‚¬ì´íŠ¸ ë¶„ì•¼ë³„ ë°ëª¨ê·¸ë˜í”½(ì„±ë³„/ì—°ë ¹) ë¶„ì„ ë°ì´í„° í˜¸ì¶œ"""
    # ì›ì¹™ì ìœ¼ë¡œëŠ” ì—¬ëŸ¬ APIë¥¼ ì¡°í•©í•´ì•¼ í•˜ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ì„±ë³„/ì—°ë ¹ ë¹„ì¤‘ ë°ì´í„°ë¥¼ ì‹œë®¬ë ˆì´ì…˜í•˜ê±°ë‚˜ 
    # ì‡¼í•‘ì¸ì‚¬ì´íŠ¸ ì¹´í…Œê³ ë¦¬ í‚¤ì›Œë“œ APIì˜ ì‘ë‹µì„ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 
    # ë³¸ êµ¬í˜„ì—ì„œëŠ” ë¶„ì•¼ë³„ ëŒ€í‘œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë¡œì§ì„ êµ¬ì„±í•©ë‹ˆë‹¤.
    return None, "ì¤€ë¹„ ì¤‘ì¸ ê¸°ëŠ¥ì…ë‹ˆë‹¤."

# --- ë°ì´í„° ì „ì²˜ë¦¬ í—¬í¼ ---
def clean_html(text):
    """HTML íƒœê·¸ ì œê±°"""
    if pd.isna(text): return ""
    return text.replace('<b>', '').replace('</b>', '').replace('&quot;', '"').replace('&lt;', '<').replace('&gt;', '>')

@st.cache_data
def convert_df(df):
    """ë°ì´í„°í”„ë ˆì„ì„ CSVë¡œ ë³€í™˜ (í•œê¸€ ê¹¨ì§ ë°©ì§€ utf-8-sig)"""
    return df.to_csv(index=False).encode('utf-8-sig')

# --- ë©”ì¸ UI ---
st.title("âš¡ ì‹¤ì‹œê°„ Naver Market Insights")
st.caption("ë¡œì»¬ íŒŒì¼ì´ ì•„ë‹Œ, ë„¤ì´ë²„ APIë¥¼ í†µí•´ ì‹¤ì‹œê°„ ë°ì´í„°ë¥¼ ì§ì ‘ ë¶„ì„í•©ë‹ˆë‹¤.")

# ì‚¬ì´ë“œë°”
# API ì¸ì¦ ìƒíƒœ ì§„ë‹¨ (ì˜¤ë¥˜ ì‹œì—ë§Œ ìƒë‹¨ ë…¸ì¶œ)
if not CLIENT_ID or not CLIENT_SECRET:
    st.sidebar.error("âŒ API ì¸ì¦ í‚¤ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.sidebar.markdown("""
        **í•´ê²° ê°€ì´ë“œ:**
        1. `naverapieda/.env` íŒŒì¼ ìƒì„± í™•ì¸
        2. íŒŒì¼ ë‚´ìš©:
           ```text
           NAVER_CLIENT_ID=ê³ ê°ì•„ì´ë””
           NAVER_CLIENT_SECRET=ë¹„ë°€í‚¤
           ```
        3. ê³µë°±ì´ë‚˜ ë”°ì˜´í‘œ ì—†ì´ ì…ë ¥ ê¶Œì¥
    """)

st.sidebar.header("ğŸ” ì‹¤ì‹œê°„ ë¶„ì„ ì„¤ì •")

target_kws = st.sidebar.text_input("ë¶„ì„ í‚¤ì›Œë“œ (ì‰¼í‘œ êµ¬ë¶„)", "ì˜¤ë©”ê°€3, ë¹„íƒ€ë¯¼D, ìœ ì‚°ê· ")
keywords = [k.strip() for k in target_kws.split(',') if k.strip()]

st.sidebar.divider()
st.sidebar.subheader("ğŸ“… ë¶„ì„ ê¸°ê°„ ì„¤ì •")
today = datetime.now()
jan_1st = datetime(today.year, 1, 1)

date_range = st.sidebar.date_input(
    "ì¡°íšŒ ê¸°ê°„ ì„ íƒ",
    value=(jan_1st, today),
    max_value=today,
    help="ì‹œì‘ì¼ê³¼ ì¢…ë£Œì¼ì„ ì„ íƒí•˜ì„¸ìš”."
)

# ë‚ ì§œ ë²”ìœ„ê°€ ì ì ˆíˆ ì„ íƒë˜ì—ˆëŠ”ì§€ í™•ì¸
if isinstance(date_range, tuple) and len(date_range) == 2:
    start_date = date_range[0].strftime("%Y-%m-%d")
    end_date = date_range[1].strftime("%Y-%m-%d")
else:
    # í•œ ë‚ ì§œë§Œ ì„ íƒëœ ê²½ìš°ë‚˜ ë¯¸ì„ íƒ ì‹œ ê¸°ë³¸ê°’ ì ìš©
    start_date = jan_1st.strftime("%Y-%m-%d")
    end_date = today.strftime("%Y-%m-%d")
    st.sidebar.warning("ì‹œì‘ì¼ê³¼ ì¢…ë£Œì¼ì„ ëª¨ë‘ ì„ íƒí•´ì£¼ì„¸ìš”.")

st.sidebar.divider()
st.sidebar.info(f"ì„ íƒëœ í‚¤ì›Œë“œ: {', '.join(keywords)}")

st.sidebar.divider()
st.sidebar.subheader("ğŸ“Š ë¶„ì„ ëª¨ë“œ ì„¤ì •")
analysis_mode = st.sidebar.radio(
    "ë¶„ì„ ëª¨ë“œ", 
    ["ì¼ë°˜ íŠ¸ë Œë“œ", "ì„±ë³„ ë¹„êµ"], 
    help="ì¼ë°˜: ì„ íƒí•œ í•„í„° ê¸°ì¤€ í†µí•© ì¶”ì´\nì„±ë³„: ë‚¨ì„± vs ì—¬ì„± ê·¸ë£¹ë³„ ìƒì„¸ íŒ¨í„´ ë¹„êµ"
)

st.sidebar.subheader("ğŸ‘¥ ì¸êµ¬ í†µê³„ í•„í„° (íŠ¸ë Œë“œ)")

# ì„±ë³„ ì„ íƒ (ì„±ë³„ ë¹„êµ ëª¨ë“œì¼ ë•ŒëŠ” ìˆ¨ê¹€/ë¹„í™œì„±)
selected_gender = ""
gender_option = "ì „ì²´"
if analysis_mode != "ì„±ë³„ ë¹„êµ":
    gender_option = st.sidebar.radio("ì„±ë³„", ["ì „ì²´", "ë‚¨ì„±", "ì—¬ì„±"], horizontal=True)
    gender_map = {"ì „ì²´": "", "ë‚¨ì„±": "m", "ì—¬ì„±": "f"}
    selected_gender = gender_map[gender_option]
else:
    st.sidebar.info("ì„±ë³„ ë¹„êµ ëª¨ë“œ: ë‚¨ì„± vs ì—¬ì„±ì„ ë¹„êµí•©ë‹ˆë‹¤.")

# ì—°ë ¹ ì„ íƒ
age_options = ["0~12ì„¸", "13~18ì„¸", "19~24ì„¸", "25~29ì„¸", "30~34ì„¸", "35~39ì„¸", "40~44ì„¸", "45~49ì„¸", "50~54ì„¸", "55~59ì„¸", "60ì„¸ ì´ìƒ"]
age_codes = ["1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11"]
age_ref = dict(zip(age_options, age_codes))
code_to_age = dict(zip(age_codes, age_options))

selected_ages = st.sidebar.multiselect("ì—°ë ¹ëŒ€ (ë‹¤ì¤‘ ì„ íƒ ê°€ëŠ¥)", age_options, placeholder="ì „ì²´ ì—°ë ¹")
selected_age_codes = [age_ref[a] for a in selected_ages] if selected_ages else []

st.sidebar.caption("ğŸ’¡ 10ë¶„ë§ˆë‹¤ ë°ì´í„°ê°€ ìµœì‹ í™”ë©ë‹ˆë‹¤.")

tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
    "ğŸ“ˆ íŠ¸ë Œë“œ ë¹„êµ", "ğŸ›ï¸ ì‹¤ì‹œê°„ ì‡¼í•‘", "ğŸ“ ì‹¤ì‹œê°„ ë¸”ë¡œê·¸", 
    "â˜• ì‹¤ì‹œê°„ ì¹´í˜", "ğŸ“° ì‹¤ì‹œê°„ ë‰´ìŠ¤", "ğŸ“Š ì‡¼í•‘ì¸ì‚¬ì´íŠ¸"
])

# Tab 1: íŠ¸ë Œë“œ ë¹„êµ
with tab1:
    st.header(f"ğŸ“ˆ ì‹¤ì‹œê°„ ê²€ìƒ‰ì–´ íŠ¸ë Œë“œ ({start_date} ~ {end_date})")
    
    # í•„í„° ì •ë³´ í‘œì‹œ
    filter_info = []
    if analysis_mode == "ì¼ë°˜ íŠ¸ë Œë“œ":
        if selected_gender: filter_info.append(f"ì„±ë³„: {gender_option}")
        if selected_ages: filter_info.append(f"ì—°ë ¹: {', '.join(selected_ages)}")
    elif analysis_mode == "ì„±ë³„ ë¹„êµ":
        filter_info.append("ë¶„ì„: ì„±ë³„ ë¹„êµ (ë‚¨ì„± vs ì—¬ì„±)")
        if selected_ages: filter_info.append(f"ì—°ë ¹: {', '.join(selected_ages)}")
        
    if filter_info:
        st.caption(f"ì ìš©ëœ í•„í„°: {' | '.join(filter_info)}")

    # --- ë°ì´í„° ìˆ˜ì§‘ ë¡œì§ ---
    df_trend = None
    err = None
    
    if analysis_mode == "ì¼ë°˜ íŠ¸ë Œë“œ":
        df_trend, err = fetch_realtime_trend(keywords, start_date, end_date, selected_gender, selected_age_codes)
    
    elif analysis_mode == "ì„±ë³„ ë¹„êµ":
        # ë‚¨ì„±/ì—¬ì„± ê°ê° í˜¸ì¶œ í›„ ë³‘í•©
        df_m, err_m = fetch_realtime_trend(keywords, start_date, end_date, "m", selected_age_codes)
        df_f, err_f = fetch_realtime_trend(keywords, start_date, end_date, "f", selected_age_codes)
        
        dfs = []
        if df_m is not None: 
            df_m['gender'] = 'ë‚¨ì„±'
            dfs.append(df_m)
        if df_f is not None: 
            df_f['gender'] = 'ì—¬ì„±'
            dfs.append(df_f)
            
        if dfs:
            df_trend = pd.concat(dfs)
        else:
            err = err_m or err_f
            
    # --- ê²°ê³¼ ì‹œê°í™” ---
    if err:
        st.error(err)
    elif df_trend is not None and not df_trend.empty:
        df_trend['period'] = pd.to_datetime(df_trend['period'])
        
        st.info(f"ğŸ“Š ì´ **{len(df_trend):,}**ê°œì˜ íŠ¸ë Œë“œ ë°ì´í„° í¬ì¸íŠ¸ê°€ ë¶„ì„ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # 1. ê·¸ë˜í”„ ê·¸ë¦¬ê¸° (ëª¨ë“œë³„ ë¶„ê¸°)
        if analysis_mode == "ì¼ë°˜ íŠ¸ë Œë“œ":
            fig1 = px.line(df_trend, x='period', y='ratio', color='keyword', 
                           title="ì‹¤ì‹œê°„ ê²€ìƒ‰ íŠ¸ë Œë“œ ì¶”ì´",
                           template="plotly_white", color_discrete_sequence=px.colors.qualitative.Prism)
        
        elif analysis_mode == "ì„±ë³„ ë¹„êµ":
            # ìƒ‰ìƒì€ í‚¤ì›Œë“œ, colì€ ì„±ë³„ë¡œ êµ¬ë¶„
            fig1 = px.line(df_trend, x='period', y='ratio', color='keyword', facet_col='gender',
                           title="ì„±ë³„ ê²€ìƒ‰ íŠ¸ë Œë“œ ë¹„êµ (Max 100 ìƒëŒ€ì§€ìˆ˜)",
                           template="plotly_white", color_discrete_sequence=px.colors.qualitative.Prism)
            # subplot ì œëª© ê¹”ë”í•˜ê²Œ
            fig1.for_each_annotation(lambda a: a.update(text=a.text.split("=")[-1]))
            
        fig1.update_layout(hovermode="x unified")
        st.plotly_chart(fig1, use_container_width=True)
        
        # ë¹„êµ ëª¨ë“œì¼ ê²½ìš° ì•ˆë‚´ ë¬¸êµ¬ ì¶”ê°€
        if analysis_mode != "ì¼ë°˜ íŠ¸ë Œë“œ":
            st.caption("""
            âš ï¸ **ì£¼ì˜**: Naver DataLab ê·¸ë˜í”„ì˜ yì¶•(ratio)ì€ í•´ë‹¹ ì¡°ê±´ ë‚´ ìµœëŒ“ê°’ì„ 100ìœ¼ë¡œ ë‘” **ìƒëŒ€ì  ì§€í‘œ**ì…ë‹ˆë‹¤. 
            ì„œë¡œ ë‹¤ë¥¸ ê·¸ë£¹ ê°„ì˜ ì ˆëŒ€ì ì¸ ê²€ìƒ‰ëŸ‰ í¬ê¸° ë¹„êµ(ì˜ˆ: ë‚¨ì„±ì˜ 50ê³¼ ì—¬ì„±ì˜ 50ì´ ê°™ì€ ê²€ìƒ‰ëŸ‰ì„)ë¥¼ ì˜ë¯¸í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. 
            ê° ê·¸ë£¹ ë‚´ì—ì„œì˜ ì¶”ì„¸ ë³€í™” íŒ¨í„´ì„ ë¹„êµí•˜ëŠ” ëª©ì ìœ¼ë¡œ í™œìš©í•˜ì„¸ìš”.
            """)
        
        col1, col2 = st.columns(2)
        with col1:
            # ê·¸ë˜í”„ 2: í‰ê·  ê²€ìƒ‰ëŸ‰ ë°” ì°¨íŠ¸
            # ê·¸ë£¹í•‘ ê¸°ì¤€ì´ ëª¨ë“œì— ë”°ë¼ ë‹¬ë¼ì§
            group_cols = ['keyword']
            if analysis_mode == "ì„±ë³„ ë¹„êµ": group_cols.append('gender')
            
            avg_df = df_trend.groupby(group_cols)['ratio'].mean().reset_index().sort_values('ratio', ascending=False)
            
            # ë°”ì°¨íŠ¸ ì‹œê°í™”
            if analysis_mode == "ì¼ë°˜ íŠ¸ë Œë“œ":
                fig2 = px.bar(avg_df, x='keyword', y='ratio', color='keyword', 
                              title="í‰ê·  ê²€ìƒ‰ í™œë™ ì ìœ ìœ¨", text_auto='.1f',
                              color_discrete_sequence=px.colors.qualitative.Safe)
            else:
                # ë¹„êµ ëª¨ë“œì—ì„œëŠ” Facet í™œìš©
                facet_c = 'gender' if analysis_mode == "ì„±ë³„ ë¹„êµ" else None
                fig2 = px.bar(avg_df, x='keyword', y='ratio', color='gender', barmode='group',
                              title="ì„±ë³„/í‚¤ì›Œë“œë³„ í‰ê·  ê²€ìƒ‰ ê°•ë„", text_auto='.1f',
                              color_discrete_sequence=px.colors.qualitative.Safe)

            st.plotly_chart(fig2, use_container_width=True)
            
        with col2:
            # í‘œ 1: ìš”ì•½ í†µê³„
            st.subheader("ğŸ“Š ë°ì´í„° ìš”ì•½ (ìƒëŒ€ ì§€í‘œ)")
            # ìš”ì•½ í†µê³„ ê·¸ë£¹í•‘
            summary = df_trend.groupby(group_cols)['ratio'].agg(['mean', 'max', 'std']).round(2)
            summary.columns = ['í‰ê· ', 'ìµœëŒ€ì¹˜', 'ë³€ë™ì„±']
            st.dataframe(summary, use_container_width=True)

        st.subheader("ğŸ“‹ ì „ì²´ ë°ì´í„° ëª©ë¡")
        st.dataframe(df_trend, use_container_width=True)
        st.download_button(
            label="ğŸ“¥ íŠ¸ë Œë“œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (CSV)",
            data=convert_df(df_trend),
            file_name=f"trend_search_{analysis_mode}_{start_date}_{end_date}.csv",
            mime="text/csv"
        )

# Tab 2: ì‹¤ì‹œê°„ ì‡¼í•‘
with tab2:
    st.header("ğŸ›ï¸ í†µí•© ì‹¤ì‹œê°„ ì‡¼í•‘ ë§ˆì¼“ í˜„í™©")
    df_shop, shop_err = fetch_realtime_shopping(keywords)
    if shop_err:
        st.error(shop_err)
    elif df_shop is not None:
        # ë°ì´í„° ì „ì²˜ë¦¬
        df_shop['lprice'] = pd.to_numeric(df_shop['lprice'], errors='coerce')
        df_shop['title'] = df_shop['title'].apply(clean_html)
        
        # KPI ì„¹ì…˜ (í†µí•©)
        m1, m2, m3 = st.columns(3)
        m1.metric("ìˆ˜ì§‘ëœ ì „ì²´ ìƒí’ˆ", f"{len(df_shop)}ê°œ")
        m2.metric("ì „ì²´ í‰ê· ê°€", f"{int(df_shop['lprice'].mean()):,}ì›")
        m3.metric("í™œì„± íŒë§¤ì²˜", f"{df_shop['mallName'].nunique()}ê°œ")
        
        col3, col4 = st.columns([2, 1])
        with col3:
            # ê·¸ë˜í”„ 3: í‚¤ì›Œë“œë³„ ê°€ê²© ë¶„í¬ ë°•ìŠ¤ í”Œë¡¯
            fig3 = px.box(df_shop, x='search_keyword', y='lprice', color='search_keyword',
                          title="í‚¤ì›Œë“œë³„ ìµœì €ê°€ ë¶„í¬ ë¹„êµ",
                          labels={'lprice': 'ìµœì €ê°€(ì›)', 'search_keyword': 'ê²€ìƒ‰ì–´'},
                          template="simple_white")
            st.plotly_chart(fig3, use_container_width=True)
        with col4:
            # ê·¸ë˜í”„ 4: í‚¤ì›Œë“œë³„ ìƒí’ˆ ë¹„ì¤‘
            kw_counts = df_shop['search_keyword'].value_counts()
            fig4 = px.pie(values=kw_counts.values, names=kw_counts.index, 
                          title="í‚¤ì›Œë“œë³„ ë°ì´í„° ë¹„ì¤‘", hole=0.4,
                          color_discrete_sequence=px.colors.qualitative.Pastel)
            st.plotly_chart(fig4, use_container_width=True)
            
        st.divider()
        st.subheader("ğŸ›’ ì‹¤ì‹œê°„ í†µí•© ì¸ê¸° ìƒí’ˆ ë¦¬ìŠ¤íŠ¸")
        st.dataframe(
            df_shop[['search_keyword', 'title', 'lprice', 'mallName', 'category1', 'link']].head(100), 
            column_config={
                "link": st.column_config.LinkColumn(
                    "ë§í¬",
                    help="í´ë¦­ì‹œ í•´ë‹¹ ìƒí’ˆ í˜ì´ì§€ë¡œ ì´ë™í•©ë‹ˆë‹¤.",
                    validate="^https://.*",
                    display_text="ë°”ë¡œê°€ê¸°"
                ),
                "lprice": st.column_config.NumberColumn(
                    "ìµœì €ê°€",
                    format="%dì›"
                )
            },
            use_container_width=True,
            hide_index=True
        )
        st.download_button(
             label="ğŸ“¥ ì‡¼í•‘ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (CSV)",
             data=convert_df(df_shop),
             file_name=f"realtime_shopping_{datetime.now().strftime('%Y%m%d')}.csv",
             mime="text/csv"
        )

# Tab 3: ì‹¤ì‹œê°„ ë¸”ë¡œê·¸
with tab3:
    st.header("ğŸ“ ì‹¤ì‹œê°„ ë¸”ë¡œê·¸ ë°˜ì‘ í†µí•© ë¶„ì„")
    df_blog, blog_err = fetch_realtime_blog(keywords)
    if blog_err:
        st.error(blog_err)
    elif df_blog is not None:
        df_blog['title'] = df_blog['title'].apply(clean_html)
        df_blog['postdate'] = pd.to_datetime(df_blog['postdate'], format='%Y%m%d', errors='coerce')
        
        st.metric("ìˆ˜ì§‘ëœ ë¸”ë¡œê·¸ ë¬¸ì„œ", f"{len(df_blog):,}ê±´")
        
        # í‚¤ì›Œë“œë³„ ê²Œì‹œë¬¼ ì¶”ì´
        blog_daily = df_blog.groupby(['postdate', 'search_keyword']).size().reset_index(name='content_count')
        fig5 = px.line(blog_daily, x='postdate', y='content_count', color='search_keyword',
                       title="í‚¤ì›Œë“œë³„ ìµœê·¼ ë¸”ë¡œê·¸ ê²Œì‹œë¬¼ ë¶„í¬",
                       labels={'postdate': 'ì‘ì„±ì¼', 'content_count': 'ê²Œì‹œë¬¼ ìˆ˜'},
                       template="plotly_white")
        st.plotly_chart(fig5, use_container_width=True)
        
        col_blog1, col_blog2 = st.columns(2)
        with col_blog1:
            # ì£¼ìš” ë¸”ë¡œê±° ë­í‚¹
            top_bloggers = df_blog['bloggername'].value_counts().head(10).reset_index()
            top_bloggers.columns = ['ë¸”ë¡œê±°ëª…', 'ê²Œì‹œë¬¼ ìˆ˜']
            fig_top_blog = px.bar(top_bloggers, x='ê²Œì‹œë¬¼ ìˆ˜', y='ë¸”ë¡œê±°ëª…', orientation='h',
                                  title="ğŸ† ì£¼ìš” í™œë™ ë¸”ë¡œê±° TOP 10",
                                  color='ê²Œì‹œë¬¼ ìˆ˜', color_continuous_scale='Magma')
            st.plotly_chart(fig_top_blog, use_container_width=True)
            
        with col_blog2:
            # ë¸”ë¡œê·¸ ì œëª© í‚¤ì›Œë“œ ë¶„ì„
            st.write("ğŸ” ë¸”ë¡œê·¸ ì œëª© í•µì‹¬ ë‹¨ì–´")
            all_blog_titles = " ".join(df_blog['title'].dropna().tolist())
            blog_words = [w for w in all_blog_titles.split() if len(w) > 1 and w not in keywords]
            from collections import Counter
            blog_word_counts = Counter(blog_words).most_common(12)
            if blog_word_counts:
                df_blog_word = pd.DataFrame(blog_word_counts, columns=['ë‹¨ì–´', 'ë¹ˆë„'])
                fig_blog_word = px.bar(df_blog_word, x='ë‹¨ì–´', y='ë¹ˆë„',
                                       title="ë¸”ë¡œê·¸ ì œëª© ë¹ˆì¶œ í‚¤ì›Œë“œ",
                                       color='ë¹ˆë„',
                                       color_continuous_scale=px.colors.sequential.PuRd)
                st.plotly_chart(fig_blog_word, use_container_width=True)
        
        st.divider()
        st.subheader("ğŸ“– ìµœê·¼ ë¸”ë¡œê·¸ ì½˜í…ì¸  í†µí•© ë¦¬ìŠ¤íŠ¸")
        st.dataframe(
            df_blog[['search_keyword', 'title', 'bloggername', 'postdate', 'link']].sort_values('postdate', ascending=False).head(100), 
            column_config={
                "link": st.column_config.LinkColumn(
                    "ë§í¬",
                    help="í´ë¦­ì‹œ í•´ë‹¹ ë¸”ë¡œê·¸ë¡œ ì´ë™í•©ë‹ˆë‹¤.",
                    validate="^https://.*",
                    display_text="ë°”ë¡œê°€ê¸°"
                ),
                "postdate": st.column_config.DateColumn(
                    "ì‘ì„±ì¼",
                    format="YYYY-MM-DD"
                )
            },
            use_container_width=True,
            hide_index=True
        )
        st.download_button(
             label="ğŸ“¥ ë¸”ë¡œê·¸ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (CSV)",
             data=convert_df(df_blog),
             file_name=f"realtime_blog_{datetime.now().strftime('%Y%m%d')}.csv",
             mime="text/csv"
        )

# Tab 4: ì‹¤ì‹œê°„ ì¹´í˜
with tab4:
    st.header("â˜• ì‹¤ì‹œê°„ ì¹´í˜ ì»¤ë®¤ë‹ˆí‹° ë°˜ì‘ í†µí•©")
    df_cafe, cafe_err = fetch_realtime_cafe(keywords)
    if cafe_err:
        st.error(cafe_err)
    elif df_cafe is not None:
        df_cafe['title'] = df_cafe['title'].apply(clean_html)
        
        st.metric("ìˆ˜ì§‘ëœ ì¹´í˜ ê²Œì‹œê¸€", f"{len(df_cafe):,}ê±´")

        # 1. í‚¤ì›Œë“œë³„ ì¹´í˜ ê²Œì‹œë¬¼ ë¹„ì¤‘ (ê¸°ì¡´)
        cafe_kw_counts = df_cafe['search_keyword'].value_counts().reset_index()
        cafe_kw_counts.columns = ['í‚¤ì›Œë“œ', 'ê²Œì‹œë¬¼ ìˆ˜']
        
        col_cafe1, col_cafe2 = st.columns(2)
        with col_cafe1:
            fig_cafe = px.bar(cafe_kw_counts, x='ê²Œì‹œë¬¼ ìˆ˜', y='í‚¤ì›Œë“œ', orientation='h',
                              title="í‚¤ì›Œë“œë³„ ì¹´í˜ í™œë™ëŸ‰ ë¹„êµ", color='í‚¤ì›Œë“œ',
                              color_discrete_sequence=px.colors.qualitative.Pastel)
            st.plotly_chart(fig_cafe, use_container_width=True)
            
        with col_cafe2:
            # 2. ì£¼ìš” í™œë™ ì¹´í˜ ë­í‚¹ (ì‹ ê·œ)
            top_cafes = df_cafe['cafename'].value_counts().head(10).reset_index()
            top_cafes.columns = ['ì¹´í˜ëª…', 'ê²Œì‹œë¬¼ ìˆ˜']
            fig_top_cafe = px.bar(top_cafes, x='ê²Œì‹œë¬¼ ìˆ˜', y='ì¹´í˜ëª…', orientation='h',
                                  title="ğŸ† ì£¼ìš” í™œë™ ì¹´í˜ TOP 10",
                                  color='ê²Œì‹œë¬¼ ìˆ˜', color_continuous_scale='Viridis')
            st.plotly_chart(fig_top_cafe, use_container_width=True)

        st.divider()
        
        # 3. ê²Œì‹œê¸€ ì œëª© í•µì‹¬ í‚¤ì›Œë“œ ë¶„ì„ (ì‹ ê·œ)
        st.subheader("ğŸ” ì¹´í˜ ê²Œì‹œê¸€ í•µì‹¬ í‚¤ì›Œë“œ ë¶„ì„ (Top 15)")
        all_titles = " ".join(df_cafe['title'].dropna().tolist())
        # ë‹¨ìˆœ í˜•íƒœì†Œ ë¶„ì„ ëŒ€ì‹  ê³µë°± ë¶„ë¦¬ ë° ê¸°ë³¸ ë¶ˆìš©ì–´ ì²˜ë¦¬
        words = [w for w in all_titles.split() if len(w) > 1 and w not in keywords]
        from collections import Counter
        word_counts = Counter(words).most_common(15)
        if word_counts:
            df_word = pd.DataFrame(word_counts, columns=['ë‹¨ì–´', 'ë¹ˆë„'])
            fig_word = px.bar(df_word, x='ë‹¨ì–´', y='ë¹ˆë„', color='ë¹ˆë„',
                              title="ì œëª© ë‚´ ë¹ˆì¶œ ë‹¨ì–´", text_auto=True,
                              color_continuous_scale='Blues')
            st.plotly_chart(fig_word, use_container_width=True)
            st.caption("ğŸ’¡ ì œëª©ì—ì„œ ì¶”ì¶œí•œ ë‹¨ì–´ ë¹ˆë„ì…ë‹ˆë‹¤. 'ì¶”ì²œ', 'ë¹„êµ', 'í›„ê¸°' ë“± ì‚¬ìš©ì ì˜ë„ë¥¼ íŒŒì•…í•´ ë³´ì„¸ìš”.")
        
        st.divider()
        st.subheader("ğŸ‘¥ ìµœì‹  í†µí•© ì¹´í˜ ê²Œì‹œë¬¼")
        st.dataframe(
            df_cafe[['search_keyword', 'title', 'cafename', 'cafeurl']].head(100),
            column_config={
                "cafeurl": st.column_config.LinkColumn(
                    "ë§í¬",
                    help="í´ë¦­ì‹œ í•´ë‹¹ ì¹´í˜ ê²Œì‹œê¸€ë¡œ ì´ë™í•©ë‹ˆë‹¤.",
                    validate="^https://.*",
                    display_text="ë°”ë¡œê°€ê¸°"
                )
            },
            use_container_width=True,
            hide_index=True
        )
        st.download_button(
             label="ğŸ“¥ ì¹´í˜ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (CSV)",
             data=convert_df(df_cafe),
             file_name=f"realtime_cafe_{datetime.now().strftime('%Y%m%d')}.csv",
             mime="text/csv"
        )

# Tab 5: ì‹¤ì‹œê°„ ë‰´ìŠ¤
with tab5:
    st.header("ğŸ“° ì‹¤ì‹œê°„ ìµœì‹  ë‰´ìŠ¤ í†µí•© ì´ìŠˆ")
    df_news, news_err = fetch_realtime_news(keywords)
    if news_err:
        st.error(news_err)
    elif df_news is not None:
        df_news['title'] = df_news['title'].apply(clean_html)
        df_news['pubDate'] = pd.to_datetime(df_news['pubDate'], errors='coerce')
        
        st.metric("ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ê¸°ì‚¬", f"{len(df_news):,}ê±´")
        
        # ì‹œê°„ëŒ€ë³„ í‚¤ì›Œë“œ ë‰´ìŠ¤ ë°œí–‰ ì¶”ì´
        news_daily = df_news.groupby([df_news['pubDate'].dt.date, 'search_keyword']).size().reset_index(name='news_count')
        news_daily.columns = ['ë°œí–‰ì¼', 'í‚¤ì›Œë“œ', 'ë‰´ìŠ¤ ìˆ˜']
        fig_news = px.bar(news_daily, x='ë°œí–‰ì¼', y='ë‰´ìŠ¤ ìˆ˜', color='í‚¤ì›Œë“œ', barmode='group',
                          title="ë‚ ì§œë³„ ë‰´ìŠ¤ ë°œí–‰ í˜„í™©",
                          template="simple_white")
        st.plotly_chart(fig_news, use_container_width=True)
        
        # ë‰´ìŠ¤ ì œëª© í‚¤ì›Œë“œ ë¶„ì„
        st.subheader("ğŸ” ì‹¤ì‹œê°„ ë‰´ìŠ¤ í•µì‹¬ í‚¤ì›Œë“œ (Hot Topics)")
        all_news_titles = " ".join(df_news['title'].dropna().tolist())
        news_words = [w for w in all_news_titles.split() if len(w) > 1 and w not in keywords]
        from collections import Counter
        news_word_counts = Counter(news_words).most_common(15)
        if news_word_counts:
            df_news_word = pd.DataFrame(news_word_counts, columns=['ë‹¨ì–´', 'ë¹ˆë„'])
            fig_news_word = px.bar(df_news_word, x='ë¹ˆë„', y='ë‹¨ì–´', orientation='h',
                                   title="ë‰´ìŠ¤ ì œëª© ë‚´ ìƒìœ„ í‚¤ì›Œë“œ", text_auto=True,
                                   color='ë¹ˆë„', color_continuous_scale='Reds')
            st.plotly_chart(fig_news_word, use_container_width=True)
            st.caption("ğŸ’¡ ë‰´ìŠ¤ì˜ í•µì‹¬ ë‹¨ì–´ë¥¼ í†µí•´ í˜„ì¬ ì‹œì¥ì˜ ì£¼ìš” ì´ìŠˆë¥¼ íŒŒì•…í•´ ë³´ì„¸ìš”.")

        st.divider()
        st.subheader("ğŸ—ï¸ ìµœì‹  ê´€ë ¨ ë‰´ìŠ¤ í†µí•© ë¦¬ìŠ¤íŠ¸")
        st.dataframe(
            df_news[['search_keyword', 'title', 'pubDate', 'link']].sort_values('pubDate', ascending=False).head(100), 
            column_config={
                "link": st.column_config.LinkColumn(
                    "ë§í¬",
                    help="í´ë¦­ì‹œ í•´ë‹¹ ë‰´ìŠ¤ ê¸°ì‚¬ë¡œ ì´ë™í•©ë‹ˆë‹¤.",
                    validate="^https://.*",
                    display_text="ë°”ë¡œê°€ê¸°"
                ),
                "pubDate": st.column_config.DatetimeColumn(
                    "ë°œí–‰ì¼ì‹œ",
                    format="YYYY-MM-DD HH:mm"
                )
            },
            use_container_width=True,
            hide_index=True
        )
        st.download_button(
             label="ğŸ“¥ ë‰´ìŠ¤ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (CSV)",
             data=convert_df(df_news),
             file_name=f"realtime_news_{datetime.now().strftime('%Y%m%d')}.csv",
             mime="text/csv"
        )

# Tab 6: ì‡¼í•‘ì¸ì‚¬ì´íŠ¸
with tab6:
    st.header("ğŸ“Š ì‡¼í•‘ì¸ì‚¬ì´íŠ¸ Deep Dive")
    
    # --- ì‡¼í•‘ì¸ì‚¬ì´íŠ¸ ì„¤ì • (íƒ­ ë‚´ë¶€ ìƒë‹¨ìœ¼ë¡œ ì´ë™) ---
    st.subheader("âš™ï¸ ë¶„ì„ ë¶„ì•¼ ì„¤ì •")
    
    # ëŒ€ë¶„ë¥˜ ì¹´í…Œê³ ë¦¬ë§Œ ì •ì˜
    CAT_OPTIONS = {
        "íŒ¨ì…˜ì˜ë¥˜": "50000000",
        "íŒ¨ì…˜ì¡í™”": "50000001",
        "í™”ì¥í’ˆ/ë¯¸ìš©": "50000002",
        "ë””ì§€í„¸/ê°€ì „": "50000003",
        "ê°€êµ¬/ì¸í…Œë¦¬ì–´": "50000004",
        "ì¶œì‚°/ìœ¡ì•„": "50000005",
        "ì‹í’ˆ": "50000006",
        "ìŠ¤í¬ì¸ /ë ˆì €": "50000007",
        "ìƒí™œ/ê±´ê°•": "50000008",
        "ì—¬ê°€/ìƒí™œí¸ì˜": "50000009",
        "ë©´ì„¸ì ": "50000010",
        "ë„ì„œ": "50000011",
        "ì§ì ‘ ì…ë ¥": "manual"
    }
    
    cat_col1, cat_col2 = st.columns([1, 2])
    
    with cat_col1:
        # ìƒí™œ/ê±´ê°•(index=8)ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ 'ì˜¤ë©”ê°€3' í‚¤ì›Œë“œì™€ ë§¤ì¹­
        selected_cat_name = st.selectbox("ëŒ€ë¶„ë¥˜ ì¹´í…Œê³ ë¦¬ ì„ íƒ", list(CAT_OPTIONS.keys()), index=8)
    
    with cat_col2:
        if selected_cat_name == "ì§ì ‘ ì…ë ¥":
            cat_id = st.text_input("ì¹´í…Œê³ ë¦¬ ID ì§ì ‘ ì…ë ¥", "50000000")
        else:
            cat_id = CAT_OPTIONS[selected_cat_name]
            st.info(f"ì„ íƒëœ ë¶„ì•¼: **{selected_cat_name}** (ID: `{cat_id}`)")

    
    st.divider()
    
    st.markdown(f"""
    **ì‡¼í•‘ì¸ì‚¬ì´íŠ¸**ëŠ” ë„¤ì´ë²„ ì‡¼í•‘ ë‚´ì—ì„œ ë°œìƒí•˜ëŠ” ì‚¬ìš©ì í´ë¦­ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë§ˆì¼“ íŠ¸ë Œë“œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
    - ì„ íƒ ì¹´í…Œê³ ë¦¬: **{selected_cat_name}** (ID: `{cat_id}`)
    - ë¶„ì„ í‚¤ì›Œë“œ: **{', '.join(keywords)}**
    """)
    
    st.subheader(f"ğŸ“ˆ ë¶„ì•¼ ë‚´ í‚¤ì›Œë“œ í´ë¦­ íŠ¸ë Œë“œ ({start_date} ~ {end_date})")
    df_ins, ins_err, api_response = fetch_shopping_insight_trend(cat_id, keywords, start_date, end_date)
    
    # ë””ë²„ê¹… ì •ë³´ í‘œì‹œ (expander)
    with st.expander("ğŸ” API ìš”ì²­/ì‘ë‹µ ì •ë³´ (ë””ë²„ê¹…)"):
        st.write("**ìš”ì²­ ì •ë³´:**")
        st.json({
            "URL": "https://openapi.naver.com/v1/datalab/shopping/category/keywords",
            "ì¹´í…Œê³ ë¦¬ ID": cat_id,
            "í‚¤ì›Œë“œ": keywords,
            "ì‹œì‘ì¼": start_date,
            "ì¢…ë£Œì¼": end_date,
            "ì‹œê°„ ë‹¨ìœ„": "date"
        })
        
        if api_response:
            st.write("**API ì‘ë‹µ:**")
            st.json(api_response)
        else:
            st.warning("API ì‘ë‹µ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # ì—ëŸ¬ ì²˜ë¦¬
    if ins_err:
        st.error(f"âŒ API í˜¸ì¶œ ì˜¤ë¥˜: {ins_err}")
        st.info("""
        **ë¬¸ì œ í•´ê²° ë°©ë²•:**
        - API ì¸ì¦ í‚¤ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”.
        - ì¹´í…Œê³ ë¦¬ IDê°€ ìœ íš¨í•œì§€ í™•ì¸í•˜ì„¸ìš”.
        - ìœ„ì˜ 'ğŸ” API ìš”ì²­/ì‘ë‹µ ì •ë³´'ë¥¼ í™•ì¸í•˜ì—¬ ìƒì„¸ ì˜¤ë¥˜ë¥¼ íŒŒì•…í•˜ì„¸ìš”.
        """)
    elif df_ins is None:
        st.warning("âš ï¸ API ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„ í™•ì¸í•˜ì„¸ìš”.")
    elif df_ins.empty:
        st.warning(f"âš ï¸ ì„ íƒí•˜ì‹  ì¹´í…Œê³ ë¦¬ **'{selected_cat_name}'** ì—ëŠ” í‚¤ì›Œë“œ **{', '.join(keywords)}** ì— ëŒ€í•œ í´ë¦­ ë°ì´í„°ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        st.info("""
        **ë°ì´í„°ê°€ ë³´ì´ì§€ ì•ŠëŠ” ì´ìœ :**
        - **ì¹´í…Œê³ ë¦¬ ë¶ˆì¼ì¹˜**: í‚¤ì›Œë“œê°€ í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì— ì†í•˜ì§€ ì•ŠëŠ” ìƒí’ˆì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì˜ˆ: 'ì›í”¼ìŠ¤'ë¥¼ 'ì‹í’ˆ'ì—ì„œ ê²€ìƒ‰)
        - **ê²€ìƒ‰ëŸ‰ ë¶€ì¡±**: í•´ë‹¹ ê¸°ê°„ ë‚´ í´ë¦­ëŸ‰ì´ ì§‘ê³„ ê¸°ì¤€ ë¯¸ë§Œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        
        **í•´ê²° ë°©ë²•:**
        1. **ì¹´í…Œê³ ë¦¬ ë³€ê²½**: í‚¤ì›Œë“œì— ë§ëŠ” ì˜¬ë°”ë¥¸ ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.
        2. **í‚¤ì›Œë“œ ë³€ê²½**: ë” ì¼ë°˜ì ì´ê±°ë‚˜ ì¸ê¸° ìˆëŠ” í‚¤ì›Œë“œë¡œ ì‹œë„í•´ë³´ì„¸ìš”.
        """)
    elif 'period' not in df_ins.columns:
        st.error(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ë°ì´í„° í˜•ì‹ì…ë‹ˆë‹¤. ì»¬ëŸ¼: {df_ins.columns.tolist()}")
        with st.expander("ğŸ” ì›ë³¸ ë°ì´í„° í™•ì¸"):
            st.dataframe(df_ins)
    else:
        # ë°ì´í„° ì „ì²˜ë¦¬
        df_ins['period'] = pd.to_datetime(df_ins['period'])
        
        st.info(f"ğŸ“Š ì´ **{len(df_ins):,}**ê°œì˜ ì‡¼í•‘ í´ë¦­ ë°ì´í„° í¬ì¸íŠ¸ê°€ ë¶„ì„ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ë©”ì¸ íŠ¸ë Œë“œ ì°¨íŠ¸
        fig_ins = px.line(df_ins, x='period', y='ratio', color='keyword',
                          title="í‚¤ì›Œë“œë³„ ì‡¼í•‘ í´ë¦­ ì§€ìˆ˜ ì¶”ì´",
                          template="plotly_white", 
                          color_discrete_sequence=px.colors.qualitative.Vivid,
                          markers=True)
        fig_ins.update_layout(
            hovermode="x unified",
            xaxis_title="ë‚ ì§œ",
            yaxis_title="í´ë¦­ ì§€ìˆ˜",
            legend_title="í‚¤ì›Œë“œ"
        )
        st.plotly_chart(fig_ins, use_container_width=True)
        st.info("ğŸ’¡ í´ë¦­ ì§€ìˆ˜ëŠ” ê¸°ê°„ ë‚´ ìµœëŒ€ ìˆ˜ì¹˜ë¥¼ 100ìœ¼ë¡œ ë‘” ìƒëŒ€ì  í™œë™ ì§€í‘œì…ë‹ˆë‹¤.")
        
        # ìƒì„¸ ë¶„ì„ ì„¹ì…˜
        st.divider()
        st.subheader("ğŸ“Š í‚¤ì›Œë“œë³„ ìƒì„¸ ë¶„ì„")
        
        col_analysis1, col_analysis2 = st.columns(2)
        
        with col_analysis1:
            # í‚¤ì›Œë“œë³„ í‰ê· /ìµœëŒ€/ìµœì†Œ í†µê³„
            stats_df = df_ins.groupby('keyword')['ratio'].agg([
                ('í‰ê·  í´ë¦­ì§€ìˆ˜', 'mean'),
                ('ìµœëŒ€ í´ë¦­ì§€ìˆ˜', 'max'),
                ('ìµœì†Œ í´ë¦­ì§€ìˆ˜', 'min'),
                ('ë³€ë™ì„±(í‘œì¤€í¸ì°¨)', 'std')
            ]).round(2).reset_index()
            
            st.write("**ğŸ“ˆ í‚¤ì›Œë“œë³„ í´ë¦­ ì§€ìˆ˜ í†µê³„**")
            st.dataframe(stats_df, use_container_width=True, hide_index=True)
            
            # í‰ê·  í´ë¦­ì§€ìˆ˜ ë°”ì°¨íŠ¸
            fig_avg = px.bar(stats_df, x='keyword', y='í‰ê·  í´ë¦­ì§€ìˆ˜', 
                            color='í‰ê·  í´ë¦­ì§€ìˆ˜',
                            title="í‚¤ì›Œë“œë³„ í‰ê·  í´ë¦­ ì§€ìˆ˜ ë¹„êµ",
                            text_auto='.1f',
                            color_continuous_scale='Blues')
            st.plotly_chart(fig_avg, use_container_width=True)
        
        with col_analysis2:
            # í‚¤ì›Œë“œë³„ í”¼í¬ ì‹œì  ì°¾ê¸°
            peak_data = []
            for kw in df_ins['keyword'].unique():
                kw_data = df_ins[df_ins['keyword'] == kw]
                peak_idx = kw_data['ratio'].idxmax()
                peak_row = kw_data.loc[peak_idx]
                peak_data.append({
                    'í‚¤ì›Œë“œ': kw,
                    'í”¼í¬ ë‚ ì§œ': peak_row['period'].strftime('%Y-%m-%d'),
                    'í”¼í¬ ì§€ìˆ˜': round(peak_row['ratio'], 2)
                })
            
            peak_df = pd.DataFrame(peak_data)
            st.write("**ğŸ”¥ í‚¤ì›Œë“œë³„ ìµœê³  ì¸ê¸° ì‹œì **")
            st.dataframe(peak_df, use_container_width=True, hide_index=True)
            
            # ìµœê·¼ 7ì¼ vs ì´ì „ 7ì¼ ë³€í™”ìœ¨
            if len(df_ins) >= 14:
                recent_change = []
                for kw in df_ins['keyword'].unique():
                    kw_data = df_ins[df_ins['keyword'] == kw].sort_values('period')
                    if len(kw_data) >= 14:
                        recent_7 = kw_data.tail(7)['ratio'].mean()
                        prev_7 = kw_data.tail(14).head(7)['ratio'].mean()
                        change_rate = ((recent_7 - prev_7) / prev_7 * 100) if prev_7 > 0 else 0
                        recent_change.append({
                            'í‚¤ì›Œë“œ': kw,
                            'ìµœê·¼ 7ì¼ í‰ê· ': round(recent_7, 2),
                            'ì´ì „ 7ì¼ í‰ê· ': round(prev_7, 2),
                            'ë³€í™”ìœ¨(%)': round(change_rate, 2)
                        })
                
                if recent_change:
                    change_df = pd.DataFrame(recent_change)
                    st.write("**ğŸ“Š ìµœê·¼ íŠ¸ë Œë“œ ë³€í™” (ìµœê·¼ 7ì¼ vs ì´ì „ 7ì¼)**")
                    st.dataframe(change_df, use_container_width=True, hide_index=True)
        
        # ì „ì²´ ë°ì´í„° í…Œì´ë¸”
        st.divider()
        with st.expander("ğŸ“‹ ì „ì²´ ë°ì´í„° ë³´ê¸°"):
            display_df = df_ins.copy()
            display_df['period'] = display_df['period'].dt.strftime('%Y-%m-%d')
            st.dataframe(display_df.sort_values(['keyword', 'period'], ascending=[True, False]), 
                        use_container_width=True, hide_index=True)
            st.download_button(
                label="ğŸ“¥ ì‡¼í•‘ì¸ì‚¬ì´íŠ¸ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (CSV)",
                data=convert_df(display_df),
                file_name=f"shopping_insight_{start_date}_{end_date}.csv",
                mime="text/csv"
            )



    st.divider()
    st.subheader("ğŸ’¡ ì‡¼í•‘ì¸ì‚¬ì´íŠ¸ í™œìš©ë²•")
    st.markdown("""
    1. **cat_id í™•ì¸ ë°©ë²•**: [ë„¤ì´ë²„ ì‡¼í•‘](https://shopping.naver.com)ì—ì„œ íŠ¹ì • ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•œ í›„ ì£¼ì†Œì°½ì˜ `cat_id=` ë’¤ì— ì˜¤ëŠ” ìˆ«ìë¥¼ ë³µì‚¬í•˜ì„¸ìš”.
    2. **íŠ¸ë Œë“œ ë¶„ì„**: í´ë¦­ ì§€ìˆ˜ê°€ ê¸‰ì¦í•˜ëŠ” ì‹œê¸°ëŠ” í•´ë‹¹ ìƒí’ˆì˜ ì œì² ì´ê±°ë‚˜ íŠ¹ì • ì´ë²¤íŠ¸ê°€ ë°œìƒí•œ ì‹œì ì…ë‹ˆë‹¤.
    3. **ë¹„ì¦ˆë‹ˆìŠ¤ ì ‘ëª©**: í´ë¦­ ì§€ìˆ˜ ë³€í™”ì— ë§ì¶° ì†Œìƒê³µì¸ì˜ ì¬ê³  í™•ë³´ ë° ì´ë²¤íŠ¸ ë§ˆì¼€íŒ…ì„ ìµœì í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """)

auth_status = "âœ… ì¸ì¦ ì™„ë£Œ" if (CLIENT_ID and CLIENT_SECRET) else "âŒ ì¸ì¦ ë¯¸ì™„ë£Œ"
st.sidebar.caption(f"ìƒíƒœ: {auth_status} | ì—…ë°ì´íŠ¸: {datetime.now().strftime('%H:%M:%S')}")
