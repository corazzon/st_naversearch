import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import os
import requests
import json
from datetime import datetime
from dotenv import load_dotenv

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="Naver API ì‹¤ì‹œê°„ ë°ì´í„° ëŒ€ì‹œë³´ë“œ",
    page_icon="âš¡",
    layout="wide"
)

# --- CSS ìŠ¤íƒ€ì¼ë§ (ì„¸ë ¨ëœ ë‹¤í¬/í™”ì´íŠ¸ ëª¨ìŒ) ---
st.markdown("""
    <style>
    .main { background-color: #f8f9fa; }
    .stMetric { background-color: #ffffff; padding: 20px; border-radius: 12px; box-shadow: 0 4px 6px rgba(0,0,0,0.05); border-top: 4px solid #00c853; }
    h1, h2, h3 { color: #1a237e; font-weight: 800; }
    .stTabs [data-baseweb="tab-list"] { gap: 10px; }
    .stTabs [data-baseweb="tab"] { 
        height: 50px; 
        background-color: #e8eaf6; 
        border-radius: 8px 8px 0 0; 
        padding: 0 25px;
        font-weight: 600;
    }
    .stTabs [aria-selected="true"] { background-color: #ffffff; border-top: 4px solid #3f51b5; color: #3f51b5; }
    div[data-testid="stSidebar"] { background-color: #ffffff; border-right: 1px solid #dee2e6; }
    </style>
""", unsafe_allow_html=True)

# --- ì¸ì¦ ë° ê²½ë¡œ ì„¤ì • ---
def get_api_keys():
    """ë„¤ì´ë²„ API í‚¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤. (Cloud Secrets ë° ë¡œì»¬ .env ì§€ì›)"""
    cid, csec = None, None
    
    # 1. Streamlit Secrets (Cloud ë°°í¬ì‹œ)
    try:
        if 'NAVER_CLIENT_ID' in st.secrets:
            cid = st.secrets['NAVER_CLIENT_ID']
            csec = st.secrets['NAVER_CLIENT_SECRET']
    except Exception:
        pass
    
    # 2. ë¡œì»¬ .env íŒŒì¼
    if not cid or not csec:
        # í˜„ì¬ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬ì— ìˆëŠ” .env íŒŒì¼ì„ ë¡œë“œ
        env_path = os.path.join(os.path.dirname(__file__), '.env')
        if os.path.exists(env_path):
            # override=Trueë¥¼ ì„¤ì •í•˜ì—¬ .env íŒŒì¼ ë³€ê²½ ì‹œ ì„œë²„ ì¬ì‹œì‘ ì—†ì´ ë°˜ì˜ë˜ë„ë¡ í•¨
            load_dotenv(env_path, override=True)
            cid = os.getenv('NAVER_CLIENT_ID')
            csec = os.getenv('NAVER_CLIENT_SECRET')

    # ê³µë°± ë° ë”°ì˜´í‘œ ì œê±° (ì‚¬ìš©ì ì…ë ¥ ì‹¤ìˆ˜ ë°©ì§€)
    if cid: cid = str(cid).strip().strip("'").strip('"')
    if csec: csec = str(csec).strip().strip("'").strip('"')
    
    return cid, csec

CLIENT_ID, CLIENT_SECRET = get_api_keys()
HEADERS = {"X-Naver-Client-Id": CLIENT_ID, "X-Naver-Client-Secret": CLIENT_SECRET, "Content-Type": "application/json"}

# --- ì‹¤ì‹œê°„ API í˜¸ì¶œ í•¨ìˆ˜ ---
@st.cache_data(ttl=600)  # 10ë¶„ ìºì‹±
def fetch_realtime_trend(keywords):
    """ë„¤ì´ë²„ ê²€ìƒ‰ì–´ íŠ¸ë Œë“œ API í˜¸ì¶œ"""
    if not CLIENT_ID or not CLIENT_SECRET: return None, "ì¸ì¦ í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    url = "https://openapi.naver.com/v1/datalab/search"
    body = {
        "startDate": "2025-01-01", "endDate": datetime.now().strftime("%Y-%m-%d"),
        "timeUnit": "date",
        "keywordGroups": [{"groupName": k, "keywords": [k]} for k in keywords]
    }
    res = requests.post(url, headers=HEADERS, data=json.dumps(body))
    if res.status_code == 200:
        dfs = [pd.DataFrame(r['data']).assign(keyword=r['title']) for r in res.json()['results']]
        return pd.concat(dfs), None
    return None, f"Trend API Error: {res.status_code} (ì¸ì¦ ì˜¤ë¥˜ ê°€ëŠ¥ì„±)" if res.status_code == 401 else f"Trend API Error: {res.status_code}"

@st.cache_data(ttl=600)
def fetch_realtime_shopping(keyword):
    """ë„¤ì´ë²„ ì‡¼í•‘ ê²€ìƒ‰ API í˜¸ì¶œ"""
    if not CLIENT_ID or not CLIENT_SECRET: return None, "ì¸ì¦ í‚¤ ë¯¸ì„¤ì •"
    url = f"https://openapi.naver.com/v1/search/shop.json?query={keyword}&display=100"
    res = requests.get(url, headers=HEADERS)
    if res.status_code == 200:
        return pd.DataFrame(res.json()['items']), None
    return None, f"Shopping API Error: {res.status_code}"

@st.cache_data(ttl=600)
def fetch_realtime_blog(keyword):
    """ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê²€ìƒ‰ API í˜¸ì¶œ"""
    if not CLIENT_ID or not CLIENT_SECRET: return None, "ì¸ì¦ í‚¤ ë¯¸ì„¤ì •"
    url = f"https://openapi.naver.com/v1/search/blog.json?query={keyword}&display=100"
    res = requests.get(url, headers=HEADERS)
    if res.status_code == 200:
        return pd.DataFrame(res.json()['items']), None
    return None, f"Blog API Error: {res.status_code}"

@st.cache_data(ttl=600)
def fetch_realtime_cafe(keyword):
    """ë„¤ì´ë²„ ì¹´í˜ ê²€ìƒ‰ API í˜¸ì¶œ"""
    if not CLIENT_ID or not CLIENT_SECRET: return None, "ì¸ì¦ í‚¤ ë¯¸ì„¤ì •"
    url = f"https://openapi.naver.com/v1/search/cafearticle.json?query={keyword}&display=100"
    res = requests.get(url, headers=HEADERS)
    if res.status_code == 200:
        return pd.DataFrame(res.json()['items']), None
    return None, f"Cafe API Error: {res.status_code}"

@st.cache_data(ttl=600)
def fetch_realtime_news(keyword):
    """ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ API í˜¸ì¶œ"""
    if not CLIENT_ID or not CLIENT_SECRET: return None, "ì¸ì¦ í‚¤ ë¯¸ì„¤ì •"
    url = f"https://openapi.naver.com/v1/search/news.json?query={keyword}&display=100"
    res = requests.get(url, headers=HEADERS)
    if res.status_code == 200:
        return pd.DataFrame(res.json()['items']), None
    return None, f"News API Error: {res.status_code}"

# --- ë°ì´í„° ì „ì²˜ë¦¬ í—¬í¼ ---
def clean_html(text):
    """HTML íƒœê·¸ ì œê±°"""
    if pd.isna(text): return ""
    return text.replace('<b>', '').replace('</b>', '').replace('&quot;', '"').replace('&lt;', '<').replace('&gt;', '>')

# --- ë©”ì¸ UI ---
st.title("âš¡ ì‹¤ì‹œê°„ Naver Market Insights")
st.caption("ë¡œì»¬ íŒŒì¼ì´ ì•„ë‹Œ, ë„¤ì´ë²„ APIë¥¼ í†µí•´ ì‹¤ì‹œê°„ ë°ì´í„°ë¥¼ ì§ì ‘ ë¶„ì„í•©ë‹ˆë‹¤.")

# ì‚¬ì´ë“œë°”
st.sidebar.header("ğŸ” ì‹¤ì‹œê°„ ë¶„ì„ ì„¤ì •")

# API ì¸ì¦ ìƒíƒœ ì§„ë‹¨ (ì˜¤ë¥˜ ì‹œì—ë§Œ ìƒë‹¨ ë…¸ì¶œ)
if not CLIENT_ID or not CLIENT_SECRET:
    st.sidebar.error("âŒ API ì¸ì¦ í‚¤ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.sidebar.markdown("""
        **í•´ê²° ê°€ì´ë“œ:**
        1. `naverapieda/.env` íŒŒì¼ ìƒì„± í™•ì¸
        2. íŒŒì¼ ë‚´ìš©:
           ```text
           NAVER_CLIENT_ID=ê³ ê°ì•„ì´ë””
           NAVER_CLIENT_SECRET=ë¹„ë°€í‚¤
           ```
        3. ê³µë°±ì´ë‚˜ ë”°ì˜´í‘œ ì—†ì´ ì…ë ¥ ê¶Œì¥
    """)

target_kws = st.sidebar.text_input("ë¶„ì„ í‚¤ì›Œë“œ (ì‰¼í‘œ êµ¬ë¶„)", "ì˜¤ë©”ê°€3, ë¹„íƒ€ë¯¼D, ìœ ì‚°ê· ")
keywords = [k.strip() for k in target_kws.split(',')]
main_kw = keywords[0] if keywords else "ì˜¤ë©”ê°€3"
st.sidebar.divider()
st.sidebar.success(f"í˜„ì¬ ì£¼ ë¶„ì„ í‚¤ì›Œë“œ: **{main_kw}**")
st.sidebar.caption("ğŸ’¡ 10ë¶„ë§ˆë‹¤ ë°ì´í„°ê°€ ìµœì‹ í™”ë©ë‹ˆë‹¤.")

tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸ“ˆ íŠ¸ë Œë“œ ë¹„êµ", "ğŸ›ï¸ ì‹¤ì‹œê°„ ì‡¼í•‘", "ğŸ“ ì‹¤ì‹œê°„ ë¸”ë¡œê·¸", "â˜• ì‹¤ì‹œê°„ ì¹´í˜", "ğŸ“° ì‹¤ì‹œê°„ ë‰´ìŠ¤"])

# Tab 1: íŠ¸ë Œë“œ ë¹„êµ
with tab1:
    st.header("ì‹¤ì‹œê°„ ê²€ìƒ‰ì–´ í™œë™ íŠ¸ë Œë“œ (2025~)")
    df_trend, err = fetch_realtime_trend(keywords)
    if err:
        st.error(err)
    elif df_trend is not None:
        df_trend['period'] = pd.to_datetime(df_trend['period'])
        
        # ê·¸ë˜í”„ 1: íŠ¸ë Œë“œ ë¼ì¸ ì°¨íŠ¸
        fig1 = px.line(df_trend, x='period', y='ratio', color='keyword', 
                       title="ì‹¤ì‹œê°„ ê²€ìƒ‰ íŠ¸ë Œë“œ ì¶”ì´",
                       template="plotly_white", color_discrete_sequence=px.colors.qualitative.Prism)
        fig1.update_layout(hovermode="x unified")
        st.plotly_chart(fig1, use_container_width=True)
        
        col1, col2 = st.columns(2)
        with col1:
            # ê·¸ë˜í”„ 2: í‰ê·  ê²€ìƒ‰ëŸ‰ ë°” ì°¨íŠ¸
            avg_df = df_trend.groupby('keyword')['ratio'].mean().reset_index().sort_values('ratio', ascending=False)
            fig2 = px.bar(avg_df, x='keyword', y='ratio', color='keyword', 
                          title="í‰ê·  ê²€ìƒ‰ í™œë™ ì ìœ ìœ¨", text_auto='.1f',
                          color_discrete_sequence=px.colors.qualitative.Safe)
            st.plotly_chart(fig2, use_container_width=True)
        with col2:
            # í‘œ 1: ìš”ì•½ í†µê³„
            st.subheader("ï¿½ ë°ì´í„° ìš”ì•½ (ìƒëŒ€ ì§€í‘œ)")
            summary = df_trend.groupby('keyword')['ratio'].agg(['mean', 'max', 'std']).round(2)
            summary.columns = ['í‰ê· ', 'ìµœëŒ€ì¹˜', 'ë³€ë™ì„±']
            st.dataframe(summary, use_container_width=True)

# Tab 2: ì‹¤ì‹œê°„ ì‡¼í•‘
with tab2:
    st.header(f"ğŸ›ï¸ '{main_kw}' ì‹¤ì‹œê°„ ë§ˆì¼“ í˜„í™©")
    df_shop, shop_err = fetch_realtime_shopping(main_kw)
    if shop_err:
        st.error(shop_err)
    elif df_shop is not None:
        # ë°ì´í„° ì „ì²˜ë¦¬
        df_shop['lprice'] = pd.to_numeric(df_shop['lprice'], errors='coerce')
        df_shop['title'] = df_shop['title'].apply(clean_html)
        
        # KPI ì„¹ì…˜
        m1, m2, m3 = st.columns(3)
        m1.metric("ì‹¤ì‹œê°„ ìˆ˜ì§‘ ìƒí’ˆ", f"{len(df_shop)}ê°œ")
        m2.metric("ì‹œì¥ í‰ê· ê°€", f"{int(df_shop['lprice'].mean()):,}ì›")
        m3.metric("í™œì„± íŒë§¤ì²˜", f"{df_shop['mallName'].nunique()}ê°œ")
        
        col3, col4 = st.columns([2, 1])
        with col3:
            # ê·¸ë˜í”„ 3: ê°€ê²© ë¶„í¬ íˆìŠ¤í† ê·¸ë¨
            fig3 = px.histogram(df_shop, x='lprice', nbins=30, 
                                title=f"'{main_kw}' ìµœì €ê°€ ë¶„í¬ (í˜„ì¬)",
                                labels={'lprice': 'ìµœì €ê°€(ì›)', 'count': 'ìƒí’ˆ ìˆ˜'},
                                color_discrete_sequence=['#43a047'], template="simple_white")
            st.plotly_chart(fig3, use_container_width=True)
        with col4:
            # ê·¸ë˜í”„ 4: ëª°ë³„ ë¹„ì¤‘ íŒŒì´ ì°¨íŠ¸
            mall_counts = df_shop['mallName'].value_counts().head(10)
            fig4 = px.pie(values=mall_counts.values, names=mall_counts.index, 
                          title="ì£¼ìš” íŒë§¤ ì‡¼í•‘ëª° (Top 10)", hole=0.4,
                          color_discrete_sequence=px.colors.sequential.Greens_r)
            st.plotly_chart(fig4, use_container_width=True)
            
        st.divider()
        st.subheader("ğŸ›’ ì‹¤ì‹œê°„ ìƒìœ„ ë…¸ì¶œ ìƒí’ˆ ë¦¬ìŠ¤íŠ¸")
        st.dataframe(df_shop[['title', 'lprice', 'mallName', 'category1', 'link']].head(50), 
                     use_container_width=True)
        
        st.subheader("ï¿½ ì¹´í…Œê³ ë¦¬ë³„ ë§ˆì¼“ ìš”ì•½")
        cat_agg = df_shop.groupby('category1')['lprice'].agg(['count', 'mean', 'max']).round(0)
        cat_agg.columns = ['ìƒí’ˆ ìˆ˜', 'í‰ê· ê°€', 'ìµœê³ ê°€']
        st.table(cat_agg)

# Tab 3: ì‹¤ì‹œê°„ ë¸”ë¡œê·¸
with tab3:
    st.header(f"ğŸ“ '{main_kw}' ì‹¤ì‹œê°„ ë¸”ë¡œê·¸ ë°˜ì‘")
    df_blog, blog_err = fetch_realtime_blog(main_kw)
    if blog_err:
        st.error(blog_err)
    elif df_blog is not None:
        # ë°ì´í„° ì „ì²˜ë¦¬
        df_blog['title'] = df_blog['title'].apply(clean_html)
        df_blog['postdate'] = pd.to_datetime(df_blog['postdate'], format='%Y%m%d', errors='coerce')
        
        # ê·¸ë˜í”„ 5: ì¼ë³„ ë¸”ë¡œê·¸ ìƒì„±ëŸ‰ (Bar)
        blog_daily = df_blog.groupby('postdate').size().reset_index(name='content_count')
        fig5 = px.bar(blog_daily, x='postdate', y='content_count', 
                      title="ìµœê·¼ ì¼ë³„ ê²Œì‹œë¬¼ ë¶„í¬",
                      labels={'postdate': 'ì‘ì„±ì¼', 'content_count': 'ê²Œì‹œë¬¼ ìˆ˜'},
                      color_discrete_sequence=['#ff8f00'])
        st.plotly_chart(fig5, use_container_width=True)
        
        st.divider()
        st.subheader("ï¿½ ìµœì‹  ë¸”ë¡œê·¸ ì½˜í…ì¸  ë¦¬ìŠ¤íŠ¸")
        st.dataframe(df_blog[['title', 'bloggername', 'postdate', 'link']].sort_values('postdate', ascending=False).head(50), 
                     use_container_width=True)
        
        st.subheader("ğŸ‘¤ í™œë°œí•œ ì •ë³´ ê³µìœ  ë¸”ë¡œê±° TOP 10")
        blogger_top = df_blog['bloggername'].value_counts().head(10).reset_index()
        blogger_top.columns = ['ë¸”ë¡œê±°ëª…', 'í¬ìŠ¤íŒ… ìˆ˜']
        st.table(blogger_top)

# Tab 4: ì‹¤ì‹œê°„ ì¹´í˜
with tab4:
    st.header(f"â˜• '{main_kw}' ì‹¤ì‹œê°„ ì¹´í˜ ì»¤ë®¤ë‹ˆí‹° ë°˜ì‘")
    df_cafe, cafe_err = fetch_realtime_cafe(main_kw)
    if cafe_err:
        st.error(cafe_err)
    elif df_cafe is not None:
        df_cafe['title'] = df_cafe['title'].apply(clean_html)
        
        # ì¹´í˜ ì´ë¦„ë³„ ë¶„í¬
        cafe_counts = df_cafe['cafename'].value_counts().head(10).reset_index()
        cafe_counts.columns = ['ì¹´í˜ëª…', 'ê²Œì‹œë¬¼ ìˆ˜']
        fig_cafe = px.bar(cafe_counts, x='ê²Œì‹œë¬¼ ìˆ˜', y='ì¹´í˜ëª…', orientation='h',
                          title="ì£¼ìš” í™œë™ ì¹´í˜ TOP 10",
                          color='ê²Œì‹œë¬¼ ìˆ˜', color_continuous_scale='Teal')
        st.plotly_chart(fig_cafe, use_container_width=True)
        
        st.divider()
        st.subheader("ğŸ‘¥ ìµœì‹  ì¹´í˜ ê²Œì‹œë¬¼ ë¦¬ìŠ¤íŠ¸")
        st.dataframe(df_cafe[['title', 'cafename', 'cafeurl']].head(50), use_container_width=True)

# Tab 5: ì‹¤ì‹œê°„ ë‰´ìŠ¤
with tab5:
    st.header(f"ğŸ“° '{main_kw}' ì‹¤ì‹œê°„ ë‰´ìŠ¤ ì´ìŠˆ")
    df_news, news_err = fetch_realtime_news(main_kw)
    if news_err:
        st.error(news_err)
    elif df_news is not None:
        df_news['title'] = df_news['title'].apply(clean_html)
        df_news['pubDate'] = pd.to_datetime(df_news['pubDate'], errors='coerce')
        
        # ì‹œê°„ëŒ€ë³„ ë‰´ìŠ¤ ë°œí–‰ ë¶„í¬
        news_daily = df_news.groupby(df_news['pubDate'].dt.date).size().reset_index(name='news_count')
        news_daily.columns = ['ë°œí–‰ì¼', 'ë‰´ìŠ¤ ìˆ˜']
        fig_news = px.area(news_daily, x='ë°œí–‰ì¼', y='ë‰´ìŠ¤ ìˆ˜', 
                           title="ìµœê·¼ ë‰´ìŠ¤ ë°œí–‰ ì¶”ì´",
                           color_discrete_sequence=['#d32f2f'])
        st.plotly_chart(fig_news, use_container_width=True)
        
        st.divider()
        st.subheader("ğŸ—ï¸ ìµœì‹  ê´€ë ¨ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸")
        st.dataframe(df_news[['title', 'pubDate', 'link']].sort_values('pubDate', ascending=False).head(50), 
                     use_container_width=True)

auth_status = "âœ… ì¸ì¦ ì™„ë£Œ" if (CLIENT_ID and CLIENT_SECRET) else "âŒ ì¸ì¦ ë¯¸ì™„ë£Œ"
st.sidebar.caption(f"ìƒíƒœ: {auth_status} | ì—…ë°ì´íŠ¸: {datetime.now().strftime('%H:%M:%S')}")
